{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PlayTennis.csv')\n",
    "print(\"\\n Input Data Set is:\\n\", df)\n",
    "t = df.keys()[-1]\n",
    "print('Target Attribute is: ', t)\n",
    "attribute_names = list(df.keys())\n",
    "attribute_names.remove(t)\n",
    "print('Predicting Attributes: ', attribute_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entropy(probs):\n",
    " return sum([-prob*math.log(prob, 2) for prob in probs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy_of_list(ls, value):\n",
    " from collections import Counter\n",
    " cnt = Counter(x for x in ls)\n",
    " print('Target attribute class count(Yes/No)=', dict(cnt))\n",
    " total_instances = len(ls)\n",
    " print(\"Total no of instances/records associated with {0} is: {1}\".format(value, total_instances))\n",
    " probs = [x / total_instances for x in cnt.values()]\n",
    " print(\"Probability of Class {0} is: {1: .4f}\".format(min(cnt), min(probs)))\n",
    " print(\"Probability of Class {0} is: {1: .4f}\".format(max(cnt), max(probs)))\n",
    " return entropy(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def information_gain(df, split_attribute, target_attribute, battr):\n",
    " print(\"\\n\\n-----Information Gain Calculation of \", split_attribute, \"--------\")\n",
    " df_split = df.groupby(split_attribute)\n",
    " glist = []\n",
    " for gname, group in df_split:\n",
    "    print('Grouped Attribute Values \\n', group)\n",
    " glist.append(gname)\n",
    "\n",
    " glist.reverse()\n",
    " nobs = len(df.index) * 1.0\n",
    " df_agg1 = df_split.agg({target_attribute: lambda\n",
    "                        x: entropy_of_list(x, glist.pop())})\n",
    " df_agg2 = df_split.agg({target_attribute: lambda x: len(x)/nobs})\n",
    "\n",
    " df_agg1.columns = ['Entropy']\n",
    " df_agg2.columns = ['Proportion']\n",
    " new_entropy = sum(df_agg1['Entropy'] *\n",
    "                   df_agg2['Proportion'])\n",
    " if battr != 'S':\n",
    "    old_entropy = entropy_of_list(df[target_attribute], 'S-'+df.iloc[0][df.columns.get_loc(battr)])\n",
    " else:\n",
    "    old_entropy = entropy_of_list(df[target_attribute], battr)\n",
    " return old_entropy - new_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(df, target_attribute, attribute_names, default_class=None, default_attr='S'):\n",
    "\n",
    " from collections import Counter\n",
    " cnt = Counter(x for x in df[target_attribute])\n",
    " if len(cnt) == 1:\n",
    "    return next(iter(cnt))\n",
    " elif df.empty or (not attribute_names):\n",
    "    return default_class\n",
    " else:\n",
    "    default_class = max(cnt.keys())\n",
    " gainz = []\n",
    " for attr in attribute_names:\n",
    "    ig = information_gain(df, attr, target_attribute, default_attr)\n",
    "    gainz.append(ig)\n",
    "    print('Information gain of', attr, 'is:', ig)\n",
    "\n",
    " index_of_max = gainz.index(max(gainz))\n",
    " best_attr = attribute_names[index_of_max]\n",
    " print(\"\\nAttribute with the maximum gain is:\", best_attr)\n",
    "\n",
    " tree = {best_attr: {}}\n",
    " remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
    "\n",
    " for attr_val, data_subset in df.groupby(best_attr):\n",
    "\n",
    "    subtree = id3(data_subset, target_attribute, remaining_attribute_names, default_class, best_attr)\n",
    "    tree[best_attr][attr_val] = subtree\n",
    " return tree\n",
    "tree = id3(df, t, attribute_names)\n",
    "print(\"\\nthe Resultant Decision Tree is:\")\n",
    "pprint(tree)\n",
    "\n",
    "\n",
    "def classify(instance, tree, default=None):\n",
    " attribute = next(iter(tree))\n",
    " if instance[attribute] in tree[attribute].keys():\n",
    "    result = tree[attribute][instance[attribute]]\n",
    "    if isinstance(result, dict):\n",
    "        return classify(instance, result)\n",
    "    else:\n",
    "        return result\n",
    " else:\n",
    "    return default\n",
    "\n",
    "\n",
    "df_new = pd.read_csv('PlayTennisTest.csv')\n",
    "df_new['predicted'] = df_new.apply(classify, axis=1, args=(tree, '?'))\n",
    "print(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify(instance, tree, default=None):\n",
    " attribute = next(iter(tree))\n",
    " if instance[attribute] in tree[attribute].keys():\n",
    "    result = tree[attribute][instance[attribute]]\n",
    "    if isinstance(result, dict):\n",
    "        return classify(instance, result)\n",
    "    else:\n",
    "        return result\n",
    " else:\n",
    "    return default\n",
    "\n",
    "\n",
    "df_new = pd.read_csv('PlayTennisTest.csv')\n",
    "df_new['predicted'] = df_new.apply(classify, axis=1, args=(tree, '?'))\n",
    "print(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " from collections import Counter\n",
    " cnt = Counter(x for x in df[target_attribute])\n",
    " if len(cnt) == 1:\n",
    "    return next(iter(cnt))\n",
    " elif df.empty or (not attribute_names):\n",
    "    return default_class\n",
    " else:\n",
    "    default_class = max(cnt.keys())\n",
    " gainz = []\n",
    " for attr in attribute_names:\n",
    "    ig = information_gain(df, attr, target_attribute, default_attr)\n",
    "    gainz.append(ig)\n",
    "    print('Information gain of', attr, 'is:', ig)\n",
    "\n",
    " index_of_max = gainz.index(max(gainz))\n",
    " best_attr = attribute_names[index_of_max]\n",
    " print(\"\\nAttribute with the maximum gain is:\", best_attr)\n",
    "\n",
    " tree = {best_attr: {}}\n",
    " remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
    "\n",
    " for attr_val, data_subset in df.groupby(best_attr):\n",
    "\n",
    "    subtree = id3(data_subset, target_attribute, remaining_attribute_names, default_class, best_attr)\n",
    "    tree[best_attr][attr_val] = subtree\n",
    " return tree\n",
    "tree = id3(df, t, attribute_names)\n",
    "print(\"\\nthe Resultant Decision Tree is:\")\n",
    "pprint(tree)\n",
    "\n",
    "\n",
    "def classify(instance, tree, default=None):\n",
    " attribute = next(iter(tree))\n",
    " if instance[attribute] in tree[attribute].keys():\n",
    "    result = tree[attribute][instance[attribute]]\n",
    "    if isinstance(result, dict):\n",
    "        return classify(instance, result)\n",
    "    else:\n",
    "        return result\n",
    " else:\n",
    "    return default\n",
    "\n",
    "\n",
    "df_new = pd.read_csv('PlayTennisTest.csv')\n",
    "df_new['predicted'] = df_new.apply(classify, axis=1, args=(tree, '?'))\n",
    "print(df_new)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
